{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efc6bdd-e5b1-41cf-95bd-516db9a5a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import chromadb\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter, HTMLSectionSplitter\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2dddf9-ab98-45c2-893b-c742884ae5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_document(splitter, doc):\n",
    "    documents = splitter.split_text(doc)\n",
    "    \n",
    "    grouped_docs = defaultdict(list)\n",
    "    \n",
    "    for doc in documents:\n",
    "        key = \" > \".join(doc.metadata.values())\n",
    "        grouped_docs[key].append(doc.page_content)\n",
    "\n",
    "    agg_grouped_docs = {}\n",
    "    for key, values in grouped_docs.items():\n",
    "        agg_grouped_docs[key] = \"\\n\\n\".join(values)\n",
    "        \n",
    "    return list(agg_grouped_docs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5629a1c2-3040-45e5-8f5e-0af28a7e306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_documents():\n",
    "    crdb = chromadb.PersistentClient(path=\"pagevector\")\n",
    "    collection = crdb.get_or_create_collection(name=\"reports\", metadata={\n",
    "        \"hnsw:M\": 32,\n",
    "        \"hnsw:search_ef\": 100\n",
    "    })\n",
    "\n",
    "    headers_to_split_on = [(\"h1\", \"Main Topic\"), (\"h2\", \"Sub Topic\")]\n",
    "    splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    pagedata = Path(\"pagedata\")\n",
    "    for source in os.listdir(pagedata):\n",
    "        print(f\"Indexing documents for {source}\")\n",
    "        for page in os.listdir(pagedata / source):\n",
    "            fullpath = os.path.join(pagedata / source / page)\n",
    "            report_id = Path(page).stem\n",
    "\n",
    "            documents = []\n",
    "            with open(fullpath) as f:\n",
    "                documents = chunk_document(splitter, f.read())\n",
    "\n",
    "            ids = []\n",
    "            crdb_docs = []\n",
    "            for i, value in enumerate(documents):\n",
    "                ids.append(f\"{i}:{report_id}\")\n",
    "                crdb_docs.append(value)\n",
    "\n",
    "            try:\n",
    "                collection.upsert(\n",
    "                    ids=ids,\n",
    "                    documents=crdb_docs,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"error upserting for {source} {report_id}: {e}\")\n",
    "\n",
    "        print(f\"Finished indexing documents for {source}. Total {collection.count()} documents\")\n",
    "\n",
    "    print(f\"Indexed {collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d680989b-8424-4ae4-9b9d-5bb17ac410a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarities(sq_conn):\n",
    "    read_cur = sq_conn.cursor()\n",
    "    update_cur = sq_conn.cursor()\n",
    "\n",
    "    crdb = chromadb.PersistentClient(path=\"pagevector\")\n",
    "    collection = crdb.get_collection(\"reports\")\n",
    "\n",
    "    headers_to_split_on = [(\"h1\", \"Main Topic\"), (\"h2\", \"Sub Topic\")]\n",
    "    splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    count = 0\n",
    "    for row in read_cur.execute(\"SELECT id, source FROM report\"):\n",
    "        report_id, source = row\n",
    "        \n",
    "        pagepath = os.path.join(\"pagedata\", source, f\"{report_id}.html\")\n",
    "        with open(pagepath) as f:\n",
    "            contents = f.read()\n",
    "            chunks = chunk_document(splitter, contents)\n",
    "\n",
    "            results = collection.query(query_texts=chunks, n_results=5)\n",
    "            ids = results[\"ids\"]\n",
    "            result_report_ids = [rid.split(\":\")[1] for id_set in ids for rid in id_set]\n",
    "            filtered_report_ids = [rid for rid in result_report_ids if rid != report_id]\n",
    "\n",
    "            result_count = Counter(filtered_report_ids)\n",
    "            top_match_ids = [match[0] for match in result_count.most_common(10)]\n",
    "\n",
    "            with sq_conn:\n",
    "                update_cur.execute(\"\"\"\n",
    "                    UPDATE report SET\n",
    "                        related_report_ids = ?\n",
    "                    WHERE id = ?\n",
    "                \"\"\", (\",\".join(top_match_ids), report_id,))\n",
    "                \n",
    "                if update_cur.rowcount != 1:\n",
    "                    raise Exception(f\"update_cur.rowcount = {update_cur.rowcount}\")\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    print(f\"Computed similarities for {count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50757d3-94ba-4e5f-ab7b-8afe54a89ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing documents for SentinelOne\n",
      "Finished indexing documents for SentinelOne. Total 1949 documents\n",
      "Indexing documents for Check Point Research\n",
      "Finished indexing documents for Check Point Research. Total 1949 documents\n",
      "Indexing documents for Subscribe to Security Magazine's RSS Feed\n",
      "Finished indexing documents for Subscribe to Security Magazine's RSS Feed. Total 2087 documents\n",
      "Indexing documents for Microsoft Security Blog\n",
      "Finished indexing documents for Microsoft Security Blog. Total 2101 documents\n",
      "Indexing documents for abuse.ch | IT-Security Blog\n",
      "Finished indexing documents for abuse.ch | IT-Security Blog. Total 2102 documents\n",
      "Indexing documents for All CISA Advisories\n",
      "Finished indexing documents for All CISA Advisories. Total 2148 documents\n",
      "Indexing documents for Unit 42\n",
      "Finished indexing documents for Unit 42. Total 2148 documents\n",
      "Indexing documents for Blog\n",
      "Finished indexing documents for Blog. Total 2171 documents\n",
      "Indexing documents for WeLiveSecurity\n",
      "Finished indexing documents for WeLiveSecurity. Total 2171 documents\n",
      "Indexing documents for Cisco Talos Blog\n",
      "Finished indexing documents for Cisco Talos Blog. Total 2180 documents\n",
      "Indexing documents for Threat Intelligence\n",
      "Finished indexing documents for Threat Intelligence. Total 2182 documents\n",
      "Indexing documents for CISA News\n",
      "Finished indexing documents for CISA News. Total 2183 documents\n",
      "Indexing documents for CISA Blog\n",
      "Finished indexing documents for CISA Blog. Total 2184 documents\n",
      "Indexing documents for Sophos News\n",
      "Finished indexing documents for Sophos News. Total 2188 documents\n",
      "Indexing documents for SANS Internet Storm Center, InfoCON: green\n",
      "Finished indexing documents for SANS Internet Storm Center, InfoCON: green. Total 2194 documents\n",
      "Indexed 2194 documents\n",
      "Computed similarities for 336 rows\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    persist_documents()\n",
    "    \n",
    "    sq_conn = sqlite3.connect(\"reports.db\")\n",
    "    try:\n",
    "        compute_similarities(sq_conn)\n",
    "    finally:\n",
    "        sq_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
