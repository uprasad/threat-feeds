{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efc6bdd-e5b1-41cf-95bd-516db9a5a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import chromadb\n",
    "from collections import defaultdict\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter, HTMLSectionSplitter\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2dddf9-ab98-45c2-893b-c742884ae5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_document(splitter, doc):\n",
    "    documents = splitter.split_text(doc)\n",
    "    \n",
    "    grouped_docs = defaultdict(list)\n",
    "    \n",
    "    for doc in documents:\n",
    "        key = \" > \".join(doc.metadata.values())\n",
    "        grouped_docs[key].append(doc.page_content)\n",
    "\n",
    "    agg_grouped_docs = {}\n",
    "    for key, values in grouped_docs.items():\n",
    "        agg_grouped_docs[key] = \"\\n\\n\".join(values)\n",
    "        \n",
    "    return agg_grouped_docs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5629a1c2-3040-45e5-8f5e-0af28a7e306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_documents():\n",
    "    crdb = chromadb.PersistentClient(path=\"pagevector\")\n",
    "    collection = crdb.get_or_create_collection(name=\"reports\")\n",
    "\n",
    "    headers_to_split_on = [(\"h1\", \"Main Topic\"), (\"h2\", \"Sub Topic\")]\n",
    "    splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    pagedata = Path(\"pagedata\")\n",
    "    for source in os.listdir(pagedata):\n",
    "        print(f\"Indexing documents for {source}\")\n",
    "        for page in os.listdir(pagedata / source):\n",
    "            fullpath = os.path.join(pagedata / source / page)\n",
    "            report_id = Path(page).stem\n",
    "\n",
    "            documents = []\n",
    "            with open(fullpath) as f:\n",
    "                documents = chunk_document(splitter, f.read())\n",
    "\n",
    "            ids = []\n",
    "            crdb_docs = []\n",
    "            for i, value in enumerate(documents):\n",
    "                ids.append(f\"{i}:{report_id}\")\n",
    "                crdb_docs.append(value)\n",
    "\n",
    "            try:\n",
    "                collection.upsert(\n",
    "                    ids=ids,\n",
    "                    documents=crdb_docs,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"error upserting for {source} {report_id}: {e}\")\n",
    "\n",
    "        print(f\"Finished indexing documents for {source}. Total {collection.count()} documents\")\n",
    "\n",
    "    print(f\"Indexed {collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50757d3-94ba-4e5f-ab7b-8afe54a89ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing documents for SentinelOne\n",
      "Finished indexing documents for SentinelOne. Total 1940 documents\n",
      "Indexing documents for Check Point Research\n",
      "Finished indexing documents for Check Point Research. Total 1940 documents\n",
      "Indexing documents for Subscribe to Security Magazine's RSS Feed\n",
      "Finished indexing documents for Subscribe to Security Magazine's RSS Feed. Total 1940 documents\n",
      "Indexing documents for Microsoft Security Blog\n",
      "Finished indexing documents for Microsoft Security Blog. Total 1940 documents\n",
      "Indexing documents for abuse.ch | IT-Security Blog\n",
      "Finished indexing documents for abuse.ch | IT-Security Blog. Total 1940 documents\n",
      "Indexing documents for All CISA Advisories\n",
      "Finished indexing documents for All CISA Advisories. Total 1940 documents\n",
      "Indexing documents for Unit 42\n",
      "Finished indexing documents for Unit 42. Total 1940 documents\n",
      "Indexing documents for Blog\n",
      "Finished indexing documents for Blog. Total 1940 documents\n",
      "Indexing documents for WeLiveSecurity\n",
      "Finished indexing documents for WeLiveSecurity. Total 1940 documents\n",
      "Indexing documents for Cisco Talos Blog\n",
      "Finished indexing documents for Cisco Talos Blog. Total 1940 documents\n",
      "Indexing documents for Threat Intelligence\n",
      "Finished indexing documents for Threat Intelligence. Total 1940 documents\n",
      "Indexing documents for CISA News\n",
      "Finished indexing documents for CISA News. Total 1940 documents\n",
      "Indexing documents for CISA Blog\n",
      "Finished indexing documents for CISA Blog. Total 1940 documents\n",
      "Indexing documents for Sophos News\n",
      "Finished indexing documents for Sophos News. Total 1940 documents\n",
      "Indexing documents for SANS Internet Storm Center, InfoCON: green\n",
      "Finished indexing documents for SANS Internet Storm Center, InfoCON: green. Total 1949 documents\n",
      "Indexed 1949 documents\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    persist_documents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
