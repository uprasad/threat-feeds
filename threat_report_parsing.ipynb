{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e69a932-fe06-468f-be55-3b9a2b0b268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘enterprise-attack.json’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/mitre/cti/master/enterprise-attack/enterprise-attack.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89b2d1c6-dcda-495f-846b-6f048fda6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "from enum import Enum\n",
    "from fake_useragent import UserAgent\n",
    "import feedparser\n",
    "import iocextract as ie\n",
    "import json\n",
    "from mitreattack.stix20 import MitreAttackData\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "import uuid\n",
    "from whoosh import index\n",
    "from whoosh import fields\n",
    "from whoosh import qparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cdbd990-8591-4acd-b7aa-848e86d6d2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/udp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/udp/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c1b8268-d7e8-4ddd-abdc-6e40bde46806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_external_ids(elems):\n",
    "    return [r.external_id for e in elems for r in e.external_references if r.source_name == 'mitre-attack']\n",
    "        \n",
    "def get_names(elems):\n",
    "    return [e.name for e in elems]\n",
    "\n",
    "# Load mitre attack data\n",
    "mitre_attack_data = MitreAttackData(\"enterprise-attack.json\")\n",
    "\n",
    "tactics = mitre_attack_data.get_tactics()\n",
    "techniques = mitre_attack_data.get_techniques()\n",
    "groups = mitre_attack_data.get_groups()\n",
    "software = mitre_attack_data.get_software()\n",
    "campaigns = mitre_attack_data.get_campaigns()\n",
    "datasources = mitre_attack_data.get_datasources()\n",
    "\n",
    "tactics_ids = set(get_external_ids(tactics))\n",
    "techniques_ids = set(get_external_ids(techniques))\n",
    "groups_names = set(get_names(groups))\n",
    "groups_ids = set(get_external_ids(groups))\n",
    "software_names = set(get_names(software))\n",
    "software_ids = set(get_external_ids(software))\n",
    "campaign_names = set(get_names(campaigns))\n",
    "campaign_ids = set(get_external_ids(campaigns))\n",
    "datasources_ids = set(get_external_ids(datasources))\n",
    "\n",
    "mitre_data = {\n",
    "    \"tactics\": tactics_ids,\n",
    "    \"techniques\": techniques_ids,\n",
    "    \"group_names\": groups_names,\n",
    "    \"group_ids\": groups_ids,\n",
    "    \"software_ids\": software_ids,\n",
    "    \"campaign_names\": campaign_names,\n",
    "    \"campaign_ids\": campaign_ids,\n",
    "    \"datasources\": datasources_ids,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d4ad9fc-2c11-4a60-a4d9-290fa949e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportType(Enum):\n",
    "    HTML = 1\n",
    "    PDF = 2\n",
    "    TEXT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68b68f92-f4d3-4922-bd70-6a779f3bf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report:\n",
    "    cve_re = re.compile(r\"\\bCVE-\\d{4}-\\d{4,}\\b\", re.IGNORECASE)\n",
    "\n",
    "    summary = None\n",
    "    ipv4s = []\n",
    "    ipv6s = []\n",
    "    sha256s = []\n",
    "    md5s = []\n",
    "    sha1s = []\n",
    "    domains = []\n",
    "    yara_rules = []\n",
    "    cves = []\n",
    "    mitre = dict()\n",
    "        \n",
    "    def __init__(self, contents, title, body, report_type, source, publish_time, url=None):\n",
    "        self.contents = contents # original contents\n",
    "        self.title = title\n",
    "        self.body = body\n",
    "        self.url = url\n",
    "        self.report_type = report_type\n",
    "        self.source = source\n",
    "        self.publish_time = publish_time\n",
    "\n",
    "        self.upload_time = time.time()\n",
    "\n",
    "    @classmethod\n",
    "    def from_url(cls, url, source, publish_time):\n",
    "        headers = {\n",
    "            \"User-Agent\": UserAgent().random,\n",
    "        }\n",
    "        resp = requests.get(url, headers=headers, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        body = soup.find('body')\n",
    "        title = soup.find('title')\n",
    "\n",
    "        return Report(resp.text, title, body.text, ReportType.HTML, source, publish_time, url=url)\n",
    "\n",
    "    def parse_iocs(self):\n",
    "        self.domains = list(set(ie.extract_urls(self.body, no_scheme=True)))\n",
    "        self.ipv4s = list(set(ie.extract_ipv4s(self.body)))\n",
    "        self.ipv6s = list(set(ie.extract_ipv6s(self.body)))\n",
    "        self.cves = list(self.cve_re.findall(self.body))\n",
    "        self.sha1s = list(set(ie.extract_sha1_hashes(self.body)))\n",
    "        self.md5s = list(set(ie.extract_md5_hashes(self.body)))\n",
    "        self.sha256s = list(set(ie.extract_sha256_hashes(self.body)))\n",
    "        self.yara_rules = list(set(ie.extract_yara_rules(self.body)))\n",
    "\n",
    "        ref_ipv4s = [ie.refang_ipv4(ipv4) for ipv4 in self.ipv4s]\n",
    "        ref_domains = [ie.refang_data(domain, no_scheme=True) for domain in self.domains]\n",
    "\n",
    "        for i in range(len(self.ipv4s)):\n",
    "            self.body = self.body.replace(self.ipv4s[i], ref_ipv4s[i])\n",
    "\n",
    "        for i in range(len(self.domains)):\n",
    "            self.body = self.body.replace(self.domains[i], ref_domains[i])\n",
    "\n",
    "        self.ipv4s = ref_ipv4s\n",
    "        self.domains = ref_domains\n",
    "\n",
    "    def parse_mitre(self):\n",
    "        # Tokenize contents\n",
    "        words = set(nltk.corpus.words.words())\n",
    "        tokens = set(nltk.tokenize.word_tokenize(self.body)).difference(words)\n",
    "        for key, values in mitre_data.items():\n",
    "            self.mitre[key] = list(tokens.intersection(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6c167fb-55f8-4da6-a54d-64065c6c713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_report(report, report_id, conn, conflict=\"REPLACE\"):\n",
    "    r = report\n",
    "\n",
    "    report_data_url = f\"pagedata/{r.source}/{report_id}.html\"\n",
    "    \n",
    "    if not os.path.exists(report_data_url):\n",
    "        os.makedirs(os.path.dirname(report_data_url), exist_ok=True)\n",
    "        with open(report_data_url, \"w\") as f:\n",
    "            f.write(r.contents)\n",
    "\n",
    "    data = {\n",
    "        \"id\": report_id,\n",
    "        \"publish_time\": r.publish_time,\n",
    "        \"title\": r.title,\n",
    "        \"summary\": r.summary,\n",
    "        \"upload_time\": r.upload_time,\n",
    "        \"source\": r.source,\n",
    "        \"ipv4s\": \",\".join(r.ipv4s),\n",
    "        \"ipv6s\": \",\".join(r.ipv6s),\n",
    "        \"urls\": \",\".join(r.domains),\n",
    "        \"yara_rules\": json.dumps(list(r.yara_rules)),\n",
    "        \"cves\": \",\".join(r.cves),\n",
    "        \"sha256s\": \",\".join(r.sha256s),\n",
    "        \"md5s\": \",\".join(r.md5s),\n",
    "        \"sha1s\": \",\".join(r.sha1s),\n",
    "        \"mitre\": json.dumps(r.mitre),\n",
    "        \"report_type\": r.report_type.name,\n",
    "        \"web_url\": r.url,\n",
    "        \"report_data_url\": report_data_url,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with conn:\n",
    "            conn.execute(f\"\"\"\n",
    "                INSERT OR {conflict} INTO report VALUES(\n",
    "                    :id,\n",
    "                    :publish_time,\n",
    "                    :title,\n",
    "                    :summary,\n",
    "                    :upload_time,\n",
    "                    :source,\n",
    "                    :ipv4s,\n",
    "                    :ipv6s,\n",
    "                    :urls,\n",
    "                    :yara_rules,\n",
    "                    :cves,\n",
    "                    :sha256s,\n",
    "                    :md5s,\n",
    "                    :sha1s,\n",
    "                    :mitre,\n",
    "                    :report_type,\n",
    "                    :web_url,\n",
    "                    :report_data_url\n",
    "                )\n",
    "            \"\"\", data)\n",
    "    except Exception as e:\n",
    "        os.remove(report_data_url)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41a3b524-b3a6-4b2d-9bc6-dae222946aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_report(report, report_id, ixwriter):\n",
    "    ixwriter.update_document(id=report_id, title=report.title, content=report.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "275c44d3-baf7-420e-9e91-ab6f3c9ab171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feed(feed, conn, ixwriter, skip_existing=True):\n",
    "    source = feed.feed.title\n",
    "    print(f\"********** Reading {len(feed.entries)} posts from {source} **********\")\n",
    "\n",
    "    for entry in feed.entries:\n",
    "        with conn:\n",
    "            row = conn.execute(\"SELECT * FROM report WHERE web_url = ?\", (entry.link,)).fetchone()\n",
    "            if row and skip_existing:\n",
    "                continue\n",
    "\n",
    "        publish_time = 0\n",
    "        if entry.published_parsed:\n",
    "            publish_time = time.mktime(entry.published_parsed)\n",
    "        try:\n",
    "            r = Report.from_url(url=entry.link, source=source, publish_time=publish_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {entry.link}, skipping: {e}\")\n",
    "            continue\n",
    "            \n",
    "        if 'title' in entry:\n",
    "            r.title = entry.title\n",
    "        if 'summary' in entry:\n",
    "            r.summary = entry.summary\n",
    "\n",
    "        r.parse_iocs()\n",
    "        r.parse_mitre()\n",
    "\n",
    "        report_id = row[0] if row else str(uuid.uuid4())\n",
    "        persist_report(r, report_id, conn)\n",
    "        index_report(r, report_id, ixwriter)\n",
    "        \n",
    "    print(f\"********** Persisted {len(feed.entries)} posts from {source} **********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae0bd4ed-7315-49f0-898d-9a127db93437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Connect to sqlite database\n",
    "    conn = sqlite3.connect(\"reports.db\")\n",
    "    \n",
    "    # Initialize database\n",
    "    with open(\"sqlite_schema.sql\") as f:\n",
    "        try:\n",
    "            with conn:\n",
    "                conn.executescript(f.read())\n",
    "        except Exception as e:\n",
    "            print(f\"error applying schema: {e}\")\n",
    "\n",
    "    # Create or reset index\n",
    "    index_dir = \"pageindex\"\n",
    "    os.makedirs(index_dir, exist_ok=True)\n",
    "\n",
    "    ixschema = fields.Schema(id=fields.ID(stored=True, unique=True), title=fields.TEXT, content=fields.TEXT(stored=True))\n",
    "    try:\n",
    "        ix = index.open_dir(index_dir, schema=ixschema, indexname=\"report\")\n",
    "    except index.EmptyIndexError:\n",
    "        ix = index.create_in(index_dir, schema=ixschema, indexname=\"report\")\n",
    "        \n",
    "    ixwriter = ix.writer()\n",
    "\n",
    "    try:\n",
    "        with open(\"feeds.txt\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"#\"):\n",
    "                    continue\n",
    "                feed = feedparser.parse(line)\n",
    "                if feed.bozo:\n",
    "                    print(f\"BOZO {line}: {feed.bozo_exception}\")\n",
    "                    continue\n",
    "                \n",
    "                process_feed(feed, conn, ixwriter, skip_existing=False)\n",
    "                print(f\"Processed feed {line}\")\n",
    "    finally:\n",
    "        ixwriter.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c9f81b9-1a0c-47dc-b4bb-282552f51a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reading 100 posts from WeLiveSecurity **********\n",
      "********** Persisted 100 posts from WeLiveSecurity **********\n",
      "Processed feed https://www.welivesecurity.com/en/rss/feed/\n",
      "********** Reading 16 posts from abuse.ch | IT-Security Blog **********\n",
      "********** Persisted 16 posts from abuse.ch | IT-Security Blog **********\n",
      "Processed feed https://abuse.ch/rss\n",
      "********** Reading 15 posts from Check Point Research **********\n",
      "********** Persisted 15 posts from Check Point Research **********\n",
      "Processed feed https://research.checkpoint.com/feed/\n",
      "********** Reading 10 posts from Sophos News **********\n",
      "********** Persisted 10 posts from Sophos News **********\n",
      "Processed feed https://news.sophos.com/en-us/feed/\n",
      "********** Reading 10 posts from SentinelOne **********\n",
      "********** Persisted 10 posts from SentinelOne **********\n",
      "Processed feed https://www.sentinelone.com/feed/\n",
      "********** Reading 15 posts from Unit 42 **********\n",
      "********** Persisted 15 posts from Unit 42 **********\n",
      "Processed feed https://unit42.paloaltonetworks.com/feed/\n",
      "********** Reading 10 posts from Blog **********\n",
      "********** Persisted 10 posts from Blog **********\n",
      "Processed feed https://www.crowdstrike.com/en-us/blog/feed\n",
      "********** Reading 10 posts from CISA Blog **********\n",
      "********** Persisted 10 posts from CISA Blog **********\n",
      "Processed feed https://www.cisa.gov/blog.xml\n",
      "********** Reading 10 posts from CISA News **********\n",
      "Error reading https://www.cisa.gov/news-events/news/cisa-update-treasury-breach, skipping: HTTPSConnectionPool(host='www.cisa.gov', port=443): Read timed out. (read timeout=10)\n",
      "Error reading https://www.cisa.gov/news-events/news/2024-year-review-highlights-cisas-achievements-reducing-risk-and-building-resilience-cybersecurity, skipping: HTTPSConnectionPool(host='www.cisa.gov', port=443): Read timed out. (read timeout=10)\n",
      "********** Persisted 10 posts from CISA News **********\n",
      "Processed feed https://www.cisa.gov/news.xml\n",
      "********** Reading 30 posts from All CISA Advisories **********\n",
      "Error reading https://www.cisa.gov/news-events/alerts/2025/03/06/cisa-releases-three-industrial-control-systems-advisories, skipping: HTTPSConnectionPool(host='www.cisa.gov', port=443): Read timed out. (read timeout=10)\n",
      "Error reading https://www.cisa.gov/news-events/ics-advisories/icsa-25-063-08, skipping: HTTPSConnectionPool(host='www.cisa.gov', port=443): Read timed out. (read timeout=10)\n",
      "Error reading https://www.cisa.gov/news-events/ics-advisories/icsa-25-063-04, skipping: HTTPSConnectionPool(host='www.cisa.gov', port=443): Read timed out. (read timeout=10)\n",
      "Error reading https://www.cisa.gov/news-events/alerts/2025/03/04/cisa-adds-four-known-exploited-vulnerabilities-catalog, skipping: HTTPSConnectionPool(host='www.cisa.gov', port=443): Read timed out. (read timeout=10)\n",
      "Error reading https://www.cisa.gov/news-events/alerts/2025/03/03/cisa-adds-five-known-exploited-vulnerabilities-catalog, skipping: HTTPSConnectionPool(host='www.cisa.gov', port=443): Read timed out. (read timeout=10)\n",
      "Error reading https://www.cisa.gov/news-events/alerts/2025/02/25/cisa-releases-two-industrial-control-systems-advisories, skipping: HTTPSConnectionPool(host='www.cisa.gov', port=443): Read timed out. (read timeout=10)\n",
      "********** Persisted 30 posts from All CISA Advisories **********\n",
      "Processed feed https://www.cisa.gov/cybersecurity-advisories/all.xml\n",
      "********** Reading 15 posts from Cisco Talos Blog **********\n",
      "********** Persisted 15 posts from Cisco Talos Blog **********\n",
      "Processed feed https://blog.talosintelligence.com/rss/\n",
      "********** Reading 11 posts from SANS Internet Storm Center, InfoCON: green **********\n",
      "********** Persisted 11 posts from SANS Internet Storm Center, InfoCON: green **********\n",
      "Processed feed https://isc.sans.edu/rssfeed_full.xml\n",
      "********** Reading 10 posts from Microsoft Security Blog **********\n",
      "********** Persisted 10 posts from Microsoft Security Blog **********\n",
      "Processed feed https://www.microsoft.com/en-us/security/blog/feed/\n",
      "********** Reading 20 posts from Threat Intelligence **********\n",
      "********** Persisted 20 posts from Threat Intelligence **********\n",
      "Processed feed https://feeds.feedburner.com/threatintelligence/pvexyqv7v0v\n",
      "********** Reading 30 posts from Subscribe to Security Magazine's RSS Feed **********\n",
      "********** Persisted 30 posts from Subscribe to Security Magazine's RSS Feed **********\n",
      "Processed feed https://www.securitymagazine.com/rss/15\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
