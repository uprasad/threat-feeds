{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e69a932-fe06-468f-be55-3b9a2b0b268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘enterprise-attack.json’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/mitre/cti/master/enterprise-attack/enterprise-attack.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b2d1c6-dcda-495f-846b-6f048fda6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "from enum import Enum\n",
    "from fake_useragent import UserAgent\n",
    "import feedparser\n",
    "import iocextract as ie\n",
    "import json\n",
    "from mitreattack.stix20 import MitreAttackData\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cdbd990-8591-4acd-b7aa-848e86d6d2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/udp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/udp/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1b8268-d7e8-4ddd-abdc-6e40bde46806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_external_ids(elems):\n",
    "    return [r.external_id for e in elems for r in e.external_references if r.source_name == 'mitre-attack']\n",
    "        \n",
    "def get_names(elems):\n",
    "    return [e.name for e in elems]\n",
    "\n",
    "# Load mitre attack data\n",
    "mitre_attack_data = MitreAttackData(\"enterprise-attack.json\")\n",
    "\n",
    "tactics = mitre_attack_data.get_tactics()\n",
    "techniques = mitre_attack_data.get_techniques()\n",
    "groups = mitre_attack_data.get_groups()\n",
    "software = mitre_attack_data.get_software()\n",
    "campaigns = mitre_attack_data.get_campaigns()\n",
    "datasources = mitre_attack_data.get_datasources()\n",
    "\n",
    "tactics_ids = set(get_external_ids(tactics))\n",
    "techniques_ids = set(get_external_ids(techniques))\n",
    "groups_names = set(get_names(groups))\n",
    "groups_ids = set(get_external_ids(groups))\n",
    "software_names = set(get_names(software))\n",
    "software_ids = set(get_external_ids(software))\n",
    "campaign_names = set(get_names(campaigns))\n",
    "campaign_ids = set(get_external_ids(campaigns))\n",
    "datasources_ids = set(get_external_ids(datasources))\n",
    "\n",
    "mitre_data = {\n",
    "    \"tactics\": tactics_ids,\n",
    "    \"techniques\": techniques_ids,\n",
    "    \"group_names\": groups_names,\n",
    "    \"group_ids\": groups_ids,\n",
    "    \"software_ids\": software_ids,\n",
    "    \"campaign_names\": campaign_names,\n",
    "    \"campaign_ids\": campaign_ids,\n",
    "    \"datasources\": datasources_ids,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4ad9fc-2c11-4a60-a4d9-290fa949e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportType(Enum):\n",
    "    HTML = 1\n",
    "    PDF = 2\n",
    "    TEXT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68b68f92-f4d3-4922-bd70-6a779f3bf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report:\n",
    "    cve_re = re.compile(r\"\\bCVE-\\d{4}-\\d{4,}\\b\", re.IGNORECASE)\n",
    "\n",
    "    summary = None\n",
    "    ipv4s = []\n",
    "    ipv6s = []\n",
    "    sha256s = []\n",
    "    md5s = []\n",
    "    sha1s = []\n",
    "    domains = []\n",
    "    yara_rules = []\n",
    "    cves = []\n",
    "    mitre = dict()\n",
    "        \n",
    "    def __init__(self, contents, title, body, report_type, source, publish_time, url=None):\n",
    "        self.contents = contents # original contents\n",
    "        self.title = title\n",
    "        self.body = body\n",
    "        self.url = url\n",
    "        self.report_type = report_type\n",
    "        self.source = source\n",
    "        self.publish_time = publish_time\n",
    "\n",
    "        self.upload_time = time.time()\n",
    "\n",
    "    @classmethod\n",
    "    def from_url(cls, url, source, publish_time):\n",
    "        headers = {\n",
    "            \"User-Agent\": UserAgent().random,\n",
    "        }\n",
    "        resp = requests.get(url, headers=headers, timeout=5)\n",
    "        resp.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        body = soup.find('body')\n",
    "        title = soup.find('title')\n",
    "\n",
    "        return Report(resp.text, title, body.text, ReportType.HTML, source, publish_time, url=url)\n",
    "\n",
    "    def parse_iocs(self):\n",
    "        self.domains = list(set(ie.extract_urls(self.body, no_scheme=True)))\n",
    "        self.ipv4s = list(set(ie.extract_ipv4s(self.body)))\n",
    "        self.ipv6s = list(set(ie.extract_ipv6s(self.body)))\n",
    "        self.cves = list(self.cve_re.findall(self.body))\n",
    "        self.sha1s = list(set(ie.extract_sha1_hashes(self.body)))\n",
    "        self.md5s = list(set(ie.extract_md5_hashes(self.body)))\n",
    "        self.sha256s = list(set(ie.extract_sha256_hashes(self.body)))\n",
    "        self.yara_rules = list(set(ie.extract_yara_rules(self.body)))\n",
    "\n",
    "        ref_ipv4s = [ie.refang_ipv4(ipv4) for ipv4 in self.ipv4s]\n",
    "        ref_domains = [ie.refang_data(domain, no_scheme=True) for domain in self.domains]\n",
    "\n",
    "        for i in range(len(self.ipv4s)):\n",
    "            self.body = self.body.replace(self.ipv4s[i], ref_ipv4s[i])\n",
    "\n",
    "        for i in range(len(self.domains)):\n",
    "            self.body = self.body.replace(self.domains[i], ref_domains[i])\n",
    "\n",
    "        self.ipv4s = ref_ipv4s\n",
    "        self.domains = ref_domains\n",
    "\n",
    "    def parse_mitre(self):\n",
    "        # Tokenize contents\n",
    "        words = set(nltk.corpus.words.words())\n",
    "        tokens = set(nltk.tokenize.word_tokenize(self.body)).difference(words)\n",
    "        for key, values in mitre_data.items():\n",
    "            self.mitre[key] = list(tokens.intersection(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6c167fb-55f8-4da6-a54d-64065c6c713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_report(report, report_id, conn, conflict=\"REPLACE\"):\n",
    "    r = report\n",
    "\n",
    "    report_data_url = f\"pagedata/{r.source}/{report_id}.html\"\n",
    "    report_body_path = f\"pagedata/{r.source}/{report_id}.body.txt\"\n",
    "    \n",
    "    if not os.path.exists(report_data_url):\n",
    "        os.makedirs(os.path.dirname(report_data_url), exist_ok=True)\n",
    "        with open(report_data_url, \"w\") as f:\n",
    "            f.write(r.contents)\n",
    "\n",
    "    if not os.path.exists(report_body_path):\n",
    "        os.makedirs(os.path.dirname(report_body_path), exist_ok=True)\n",
    "        with open(report_body_path, \"w\") as f:\n",
    "            f.write(r.body)\n",
    "    \n",
    "    data = {\n",
    "        \"id\": report_id,\n",
    "        \"publish_time\": r.publish_time,\n",
    "        \"title\": r.title,\n",
    "        \"summary\": r.summary,\n",
    "        \"upload_time\": r.upload_time,\n",
    "        \"source\": r.source,\n",
    "        \"ipv4s\": \",\".join(r.ipv4s),\n",
    "        \"ipv6s\": \",\".join(r.ipv6s),\n",
    "        \"urls\": \",\".join(r.domains),\n",
    "        \"yara_rules\": json.dumps(list(r.yara_rules)),\n",
    "        \"cves\": \",\".join(r.cves),\n",
    "        \"sha256s\": \",\".join(r.sha256s),\n",
    "        \"md5s\": \",\".join(r.md5s),\n",
    "        \"sha1s\": \",\".join(r.sha1s),\n",
    "        \"mitre\": json.dumps(r.mitre),\n",
    "        \"report_type\": r.report_type.name,\n",
    "        \"web_url\": r.url,\n",
    "        \"report_data_url\": report_data_url,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with conn:\n",
    "            conn.execute(f\"\"\"\n",
    "                INSERT OR {conflict} INTO report VALUES(\n",
    "                    :id,\n",
    "                    :publish_time,\n",
    "                    :title,\n",
    "                    :summary,\n",
    "                    :upload_time,\n",
    "                    :source,\n",
    "                    :ipv4s,\n",
    "                    :ipv6s,\n",
    "                    :urls,\n",
    "                    :yara_rules,\n",
    "                    :cves,\n",
    "                    :sha256s,\n",
    "                    :md5s,\n",
    "                    :sha1s,\n",
    "                    :mitre,\n",
    "                    :report_type,\n",
    "                    :web_url,\n",
    "                    :report_data_url\n",
    "                )\n",
    "            \"\"\", data)\n",
    "    except Exception as e:\n",
    "        os.remove(report_data_url)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "275c44d3-baf7-420e-9e91-ab6f3c9ab171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feed(feed, conn, skip_existing=True):\n",
    "    source = feed.feed.title\n",
    "    print(f\"********** Reading {len(feed.entries)} posts from {source} **********\")\n",
    "\n",
    "    for entry in feed.entries:\n",
    "        with conn:\n",
    "            row = conn.execute(\"SELECT * FROM report WHERE web_url = ?\", (entry.link,)).fetchone()\n",
    "            if row:\n",
    "                print(f\"{entry.link} already processed. UUID: {row[0]}\")\n",
    "                if skip_existing:\n",
    "                    continue\n",
    "\n",
    "        publish_time = 0\n",
    "        if entry.published_parsed:\n",
    "            publish_time = time.mktime(entry.published_parsed)\n",
    "        try:\n",
    "            r = Report.from_url(url=entry.link, source=source, publish_time=publish_time)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {entry.link}, skipping: {e}\")\n",
    "            continue\n",
    "            \n",
    "        if 'title' in entry:\n",
    "            r.title = entry.title\n",
    "        if 'summary' in entry:\n",
    "            r.summary = entry.summary\n",
    "\n",
    "        r.parse_iocs()\n",
    "        r.parse_mitre()\n",
    "\n",
    "        report_id = row[0] if row else str(uuid.uuid4())\n",
    "        persist_report(r, report_id, conn)\n",
    "        \n",
    "    print(f\"********** Persisted {len(feed.entries)} posts from {source} **********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae0bd4ed-7315-49f0-898d-9a127db93437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Connect to sqlite database\n",
    "    conn = sqlite3.connect(\"reports.db\")\n",
    "    \n",
    "    # Initialize database\n",
    "    with open(\"sqlite_schema.sql\") as f:\n",
    "        try:\n",
    "            with conn:\n",
    "                conn.executescript(f.read())\n",
    "        except Exception as e:\n",
    "            print(f\"error applying schema: {e}\")\n",
    "\n",
    "    with open(\"feeds.txt\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            feed = feedparser.parse(line)\n",
    "            if feed.bozo:\n",
    "                print(f\"BOZO {line}: {feed.bozo_exception}\")\n",
    "                continue\n",
    "            \n",
    "            process_feed(feed, conn, skip_existing=False)\n",
    "            print(f\"Processed feed {line}\")\n",
    "    \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f81b9-1a0c-47dc-b4bb-282552f51a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
